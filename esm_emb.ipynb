{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f628c4d",
   "metadata": {},
   "source": [
    "# Reproduce DDGemb method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b63206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84817ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\badea\\AppData\\Local\\Temp\\ipykernel_14028\\2789855006.py:2: DtypeWarning: Columns (23,24,25,26,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_fireprot = pd.read_csv(path + 'fireprotdb_results.csv')\n"
     ]
    }
   ],
   "source": [
    "path = 'data/'\n",
    "df_fireprot = pd.read_csv(path + 'fireprotdb_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfbd3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>chain</th>\n",
       "      <th>position</th>\n",
       "      <th>wild_type</th>\n",
       "      <th>mutation</th>\n",
       "      <th>ddG</th>\n",
       "      <th>dTm</th>\n",
       "      <th>...</th>\n",
       "      <th>technique</th>\n",
       "      <th>technique_details</th>\n",
       "      <th>pH</th>\n",
       "      <th>tm</th>\n",
       "      <th>notes</th>\n",
       "      <th>publication_doi</th>\n",
       "      <th>publication_pubmed</th>\n",
       "      <th>hsw_job_id</th>\n",
       "      <th>datasets</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LL000001</td>\n",
       "      <td>Haloalkane dehalogenase</td>\n",
       "      <td>P59336</td>\n",
       "      <td>1CQW</td>\n",
       "      <td>A</td>\n",
       "      <td>245</td>\n",
       "      <td>V</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xfyu58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LL000002</td>\n",
       "      <td>Haloalkane dehalogenase</td>\n",
       "      <td>P59336</td>\n",
       "      <td>1CQW</td>\n",
       "      <td>A</td>\n",
       "      <td>95</td>\n",
       "      <td>L</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xfyu58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LL000004</td>\n",
       "      <td>Haloalkane dehalogenase</td>\n",
       "      <td>P59336</td>\n",
       "      <td>1CQW</td>\n",
       "      <td>A</td>\n",
       "      <td>176</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xfyu58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LL000005</td>\n",
       "      <td>Haloalkane dehalogenase</td>\n",
       "      <td>P59336</td>\n",
       "      <td>1CQW</td>\n",
       "      <td>A</td>\n",
       "      <td>171</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xfyu58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LL000006</td>\n",
       "      <td>Haloalkane dehalogenase</td>\n",
       "      <td>P59336</td>\n",
       "      <td>1CQW</td>\n",
       "      <td>A</td>\n",
       "      <td>148</td>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xfyu58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_id             protein_name uniprot_id pdb_id chain  position  \\\n",
       "0      LL000001  Haloalkane dehalogenase     P59336   1CQW     A       245   \n",
       "1      LL000002  Haloalkane dehalogenase     P59336   1CQW     A        95   \n",
       "2      LL000004  Haloalkane dehalogenase     P59336   1CQW     A       176   \n",
       "3      LL000005  Haloalkane dehalogenase     P59336   1CQW     A       171   \n",
       "4      LL000006  Haloalkane dehalogenase     P59336   1CQW     A       148   \n",
       "\n",
       "  wild_type mutation  ddG  dTm  ...  technique  technique_details  pH    tm  \\\n",
       "0         V        L  NaN  2.1  ...        NaN                NaN NaN  52.5   \n",
       "1         L        V  NaN -0.4  ...        NaN                NaN NaN  50.0   \n",
       "2         C        F  NaN  5.2  ...        NaN                NaN NaN  55.6   \n",
       "3         G        Q  NaN  3.1  ...        NaN                NaN NaN  53.5   \n",
       "4         T        L  NaN  1.1  ...        NaN                NaN NaN  51.5   \n",
       "\n",
       "   notes  publication_doi  publication_pubmed  hsw_job_id datasets  \\\n",
       "0    NaN              NaN                 NaN      xfyu58      NaN   \n",
       "1    NaN              NaN                 NaN      xfyu58      NaN   \n",
       "2    NaN              NaN                 NaN      xfyu58      NaN   \n",
       "3    NaN              NaN                 NaN      xfyu58      NaN   \n",
       "4    NaN              NaN                 NaN      xfyu58      NaN   \n",
       "\n",
       "                                            sequence  \n",
       "0  MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...  \n",
       "1  MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...  \n",
       "2  MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...  \n",
       "3  MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...  \n",
       "4  MSEIGTGFPFDPHYVEVLGERMHYVDVGPRDGTPVLFLHGNPTSSY...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fireprot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67644f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['experiment_id', 'protein_name', 'uniprot_id', 'pdb_id', 'chain',\n",
      "       'position', 'wild_type', 'mutation', 'ddG', 'dTm', 'is_curated', 'type',\n",
      "       'derived_type', 'interpro_families', 'conservation', 'is_essential',\n",
      "       'correlated_positions', 'is_back_to_consensus', 'secondary_structure',\n",
      "       'asa', 'is_in_catalytic_pocket', 'is_in_tunnel_bottleneck', 'b_factor',\n",
      "       'method', 'method_details', 'technique', 'technique_details', 'pH',\n",
      "       'tm', 'notes', 'publication_doi', 'publication_pubmed', 'hsw_job_id',\n",
      "       'datasets', 'sequence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_fireprot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d8b205d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subtilisin-chymotrypsin inhibitor-2A</td>\n",
       "      <td>12276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tyrosine-protein kinase Fyn</td>\n",
       "      <td>2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Halohydrin dehalogenase</td>\n",
       "      <td>2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADHA</td>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Immunoglobulin G-binding protein G</td>\n",
       "      <td>2220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Ferredoxin, heterocyst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Non-specific lipid-transfer protein</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>S-adenosylmethionine synthase isoform type-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Tetracycline repressor protein class D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>High-potential iron-sulfur protein isozyme I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     protein_name  count\n",
       "0            Subtilisin-chymotrypsin inhibitor-2A  12276\n",
       "1                     Tyrosine-protein kinase Fyn   2488\n",
       "2                         Halohydrin dehalogenase   2480\n",
       "3                                            ADHA   2404\n",
       "4              Immunoglobulin G-binding protein G   2220\n",
       "..                                            ...    ...\n",
       "205                        Ferredoxin, heterocyst      1\n",
       "206           Non-specific lipid-transfer protein      1\n",
       "207  S-adenosylmethionine synthase isoform type-1      1\n",
       "208        Tetracycline repressor protein class D      1\n",
       "209  High-potential iron-sulfur protein isozyme I      1\n",
       "\n",
       "[210 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_counts_1 = df_fireprot[\"protein_name\"].value_counts().reset_index()\n",
    "protein_counts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "540a919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['experiment_id', 'protein_name', 'uniprot_id', 'pdb_id', 'chain',\n",
    "       'position', 'wild_type', 'mutation', 'ddG', 'sequence']\n",
    "df_fireprot = df_fireprot[-df_fireprot['ddG'].isna()]\n",
    "df_subset = df_fireprot[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "382dc82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2IMM', '1YYX'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset[df_subset[\"protein_name\"].isna()].pdb_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7359a88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 39177 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset contains {} rows\".format(len(df_subset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52e2485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EsmModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7b6cb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Harvard\\Spring\\BMI707\\BMI707FinalProject\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\badea\\.cache\\huggingface\\hub\\models--facebook--esm2_t6_8M_UR50D. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd5d87aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = EsmModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a7e2ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([448, 320])\n"
     ]
    }
   ],
   "source": [
    "seq_test = df_subset.iloc[0][\"sequence\"]\n",
    "\n",
    "inputs = tokenizer(seq_test, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    pooled_output = last_hidden_states[:,1:-1,:].squeeze(0)\n",
    "    print(pooled_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "382bd883",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output = pooled_output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3682ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((448, 320), 448)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape, len(seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "127a0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DDGPredictor(nn.Module):\n",
    "    def __init__(self, \n",
    "                esm_model_name=\"facebook/esm2_t6_8M_UR50D\", \n",
    "                embedding_dim=320, \n",
    "                conv_channels=128, \n",
    "                heads=4, \n",
    "                ffn_dim=256):\n",
    "        super(DDGPredictor, self).__init__()\n",
    "        \n",
    "        # Load pretrained ESM2 model\n",
    "        self.esm_model = EsmModel.from_pretrained(esm_model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(esm_model_name)\n",
    "        \n",
    "        # Freeze ESM model if needed\n",
    "        for param in self.esm_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # 1D Conv Layer\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=embedding_dim, \n",
    "            out_channels=conv_channels, \n",
    "            kernel_size=3, \n",
    "            padding=1\n",
    "            )\n",
    "        \n",
    "        # Multi-Head Attention\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=conv_channels, \n",
    "            num_heads=heads, \n",
    "            batch_first=True)\n",
    "        \n",
    "        # Position-wise FFN\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(conv_channels, ffn_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ffn_dim, conv_channels)\n",
    "        )\n",
    "        \n",
    "        # Pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        # Dense layers for final regression\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(conv_channels * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def get_embeddings(self, seqs):\n",
    "        # Tokenize\n",
    "        tokens = self.tokenizer(seqs, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.esm_model(**tokens)\n",
    "        # Extract per-residue embeddings\n",
    "        return outputs.last_hidden_state[:,1:-1,:]  # shape: (batch, L, 320)\n",
    "    \n",
    "    def forward(self, wt_seqs, mut_seqs):\n",
    "        # Get ESM embeddings\n",
    "        emb_wt = self.get_embeddings(wt_seqs)\n",
    "        emb_mut = self.get_embeddings(mut_seqs)\n",
    "        \n",
    "        # Take difference\n",
    "        d = emb_wt - emb_mut  # shape: (B, L, 320)\n",
    "        \n",
    "        # Conv1D expects (B, C, L)\n",
    "        c = self.conv1d(d.transpose(1, 2)).transpose(1, 2)  # shape: (B, L, conv_channels)\n",
    "        \n",
    "        # Multihead attention: q, k, v = c\n",
    "        m, _ = self.attention(c, c, c)\n",
    "        \n",
    "        # Residual connection\n",
    "        z = c + m\n",
    "        \n",
    "        # Feedforward with residual\n",
    "        p = self.ffn(z)\n",
    "        f = z + p\n",
    "        \n",
    "        # Pooling\n",
    "        f_t = f.transpose(1, 2)  # (B, C, L)\n",
    "        gp = self.global_avg_pool(f_t).squeeze(-1)  # (B, C)\n",
    "        gm = self.global_max_pool(f_t).squeeze(-1)  # (B, C)\n",
    "        \n",
    "        conc = torch.cat([gp, gm], dim=1)  # (B, 2C)\n",
    "        \n",
    "        # Final regression\n",
    "        ddg_pred = self.regressor(conc).squeeze(-1)\n",
    "        return ddg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df56bbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DDGPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define wt_seqs_batch and mut_seqs_batch, ddG_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d12ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DDGPredictor()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    pred = model(wt_seqs_batch, mut_seqs_batch)\n",
    "    loss = loss_fn(pred, ddG_true)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
