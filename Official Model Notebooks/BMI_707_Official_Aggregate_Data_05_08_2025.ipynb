{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN4uNvNjJi/eP/ZEver+9oY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Aggregate PKL Files (Class: DeltaDDGDataset)\n","\n","05_08_2025\n","\n","\n","\n","*   Seshu has loaded structures as graph objects for proteins (0-117)\n","*   Val has from ~85 - 140 but split into 5 different folds of saved PKL files\n","\n","Objective: Merge all results into a full saved PKL file that can then be split into respective train, test, split DeltaDDGDataset objects.\n","\n"],"metadata":{"id":"BGpb4H6-K7Uf"}},{"cell_type":"code","source":["!pip install torch_geometric\n","!pip install biopython\n","!pip install networkx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ekttCEqUSh3G","executionInfo":{"status":"ok","timestamp":1746747941702,"user_tz":240,"elapsed":14602,"user":{"displayName":"Shyam Chandra","userId":"03777450140547744248"}},"outputId":"2839abc7-1dd9-4623-91d4-7de858f45b9d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m61.4/63.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.6.1\n","Collecting biopython\n","  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n","Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: biopython\n","Successfully installed biopython-1.85\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.data import Data, DataLoader\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import requests\n","import networkx as nx\n","from scipy.spatial.distance import euclidean\n","from Bio.PDB import PDBParser, PDBList\n","from torch_geometric.nn import GCNConv, GraphNorm, global_mean_pool\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from torch.utils.data import Dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"caLZvXO7SgKj","executionInfo":{"status":"ok","timestamp":1746747985802,"user_tz":240,"elapsed":33165,"user":{"displayName":"Shyam Chandra","userId":"03777450140547744248"}},"outputId":"4014d456-854c-4ec3-a781-f6e1fecb95c4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gEsttjCbK6tl","executionInfo":{"status":"ok","timestamp":1746747988846,"user_tz":240,"elapsed":1,"user":{"displayName":"Shyam Chandra","userId":"03777450140547744248"}}},"outputs":[],"source":["class DeltaDDGDataset(Dataset):\n","    def __init__(self, all_results):\n","        self.all_results = all_results\n","\n","    def __len__(self):\n","        return len(self.all_results)\n","\n","    def __getitem__(self, idx):\n","        return self.all_results[idx]\n","\n","    def save(self, path):\n","        data = {\n","            'all_results': self.all_results,\n","        }\n","        torch.save(data, path)\n","\n","    @classmethod\n","    def load(cls, path):\n","        data = torch.load(path, weights_only=False)\n","        obj = cls.__new__(cls)\n","        obj.all_results = data['all_results']\n","        return obj"]},{"cell_type":"code","source":["fold_3_dataset_loaded = torch.load(\"/content/drive/MyDrive/BMI_707_Project/707_Files_for_Colab/Data_To_Aggregate/fold_3_dataset_no_overlap.pkl\", weights_only=False)\n","\n","fold_1_2_4_dataset_loaded = torch.load(\"/content/drive/MyDrive/BMI_707_Project/707_Files_for_Colab/Data_To_Aggregate/fold_1_2_4_no_overlap_dataset.pkl\", weights_only=False)\n","\n","fold_yolo_loaded = torch.load(\"/content/drive/MyDrive/BMI_707_Project/707_Files_for_Colab/Data_To_Aggregate/yolo_i_hope_this_works.pkl\", weights_only=False)\n"],"metadata":{"id":"J4Pz2wjES9Y0","executionInfo":{"status":"ok","timestamp":1746748583145,"user_tz":240,"elapsed":9361,"user":{"displayName":"Shyam Chandra","userId":"03777450140547744248"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["folds_total_results = (\n","    fold_3_dataset_loaded.all_results +\n","    fold_1_2_4_dataset_loaded.all_results +\n","    fold_yolo_loaded.all_results\n",")\n"],"metadata":{"id":"lS4O3eGCU__4","executionInfo":{"status":"ok","timestamp":1746749242377,"user_tz":240,"elapsed":3,"user":{"displayName":"Shyam Chandra","userId":"03777450140547744248"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Deduplicate based on mt_sequence\n","indices = []\n","mt_seqs = []\n","for i, entry in enumerate(folds_total_results):\n","    indices.append(i)\n","    mt_seqs.append(entry[3][\"mt_sequence\"])\n","\n","df = pd.DataFrame({\"index\": indices, \"mt_sequence\": mt_seqs})\n","df.drop_duplicates(\"mt_sequence\", inplace=True)\n","\n","folds_total_deduped = []\n","for i, entry in enumerate(folds_total_results):\n","    if i in df[\"index\"].values:\n","        folds_total_deduped.append(entry)\n","\n","# Wrap in dataset and save\n","folds_total_dataset = DeltaDDGDataset(folds_total_deduped)\n","torch.save(folds_total_dataset, \"/content/drive/MyDrive/BMI_707_Project/707_Files_for_Colab/folds_total_dataset_yuh.pkl\")"],"metadata":{"id":"lgs6VPfLVGcB","executionInfo":{"status":"ok","timestamp":1746749261235,"user_tz":240,"elapsed":3718,"user":{"displayName":"Shyam Chandra","userId":"03777450140547744248"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#### validate loading and veriyfing that there are no duplicates\n","\n","# Step 1: Load dataset\n","dataset_path = \"/content/drive/MyDrive/BMI_707_Project/707_Files_for_Colab/folds_total_dataset_yuh.pkl\"\n","loaded_dataset = torch.load(dataset_path, weights_only=False)\n","\n","# Step 2: Extract all mt_sequences\n","mt_seqs = [entry[3][\"mt_sequence\"] for entry in loaded_dataset.all_results]\n","\n","# Step 3: Create DataFrame to check for duplicates\n","df = pd.DataFrame({\"mt_sequence\": mt_seqs})\n","\n","# Step 4: Check for duplicates\n","num_total = len(df)\n","num_unique = df[\"mt_sequence\"].nunique()\n","num_duplicates = num_total - num_unique\n","\n","print(f\"Total entries: {num_total}\")\n","print(f\"Unique mt_sequences: {num_unique}\")\n","print(f\"Duplicate entries: {num_duplicates}\")\n","\n","if num_duplicates == 0:\n","    print(\"✅ No duplicates found.\")\n","else:\n","    print(\"❌ Duplicates exist.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xcvfo9mWXrYf","executionInfo":{"status":"ok","timestamp":1746749452340,"user_tz":240,"elapsed":2646,"user":{"displayName":"Shyam Chandra","userId":"03777450140547744248"}},"outputId":"bcca7a59-56f9-4e9a-cc63-47ccf1820a2a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Total entries: 3763\n","Unique mt_sequences: 3763\n","Duplicate entries: 0\n","✅ No duplicates found.\n"]}]},{"cell_type":"code","source":["# Step 2: Load the dataset\n","dataset_path = \"/content/drive/MyDrive/BMI_707_Project/707_Files_for_Colab/folds_total_dataset_yuh.pkl\"\n","dataset = torch.load(dataset_path, weights_only=False)\n","all_data = dataset.all_results\n","\n","# Step 3: Train/Val/Test split using sklearn\n","train_data, temp_data = train_test_split(all_data, test_size=0.2, random_state=42)\n","val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n","\n","# Step 4: Wrap and save each split\n","DeltaDDGDataset(train_data).save(\"/content/drive/MyDrive/BMI_707_Project/707_Files_for_Colab/train_dataset.pkl\")\n","DeltaDDGDataset(val_data).save(\"/content/drive/MyDrive/BMI_707_Project/707_Files_for_Colab/val_dataset.pkl\")\n","DeltaDDGDataset(test_data).save(\"/content/drive/MyDrive/BMI_707_Project/707_Files_for_Colab/test_dataset.pkl\")\n","\n","print(f\"✅ Splits saved! Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2gS_8mJZK2S","executionInfo":{"status":"ok","timestamp":1746749832632,"user_tz":240,"elapsed":5619,"user":{"displayName":"Shyam Chandra","userId":"03777450140547744248"}},"outputId":"a7bad267-840b-45f0-fdde-e0ee63913573"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Splits saved! Train: 3010, Val: 376, Test: 377\n"]}]},{"cell_type":"code","source":["fold_3_dataset_loaded_last = torch.load(\"/content/drive/MyDrive/707/data/fold_3_dataset_last.pkl\", weights_only=False)\n","fold_3_dataset_loaded_first = torch.load(\"/content/drive/MyDrive/707/data/first_part_dataset_F3.pkl\", weights_only=False)\n","\n","fold_3_overlap = fold_3_dataset_loaded_last.all_results + fold_3_dataset_loaded_first.all_results\n","\n","df_3 = pd.DataFrame()\n","indices= []\n","mt_seqs = []\n","for i in range(len(fold_3_overlap)):\n","  indices.append(i)\n","  mt_seqs.append(fold_3_overlap[i][3][\"mt_sequence\"])\n","\n","df_3 = pd.DataFrame({\n","    \"index\": indices,\n","    \"mt_sequence\": mt_seqs\n","})\n","\n","df_3.drop_duplicates(\"mt_sequence\", inplace=True)\n","\n","fold_3_no_overlap = []\n","for i,entry in enumerate(fold_3_overlap):\n","  if i in df_3[\"index\"].values:\n","    fold_3_no_overlap.append(entry)\n","\n","len(fold_3_no_overlap)\n","\n","fold_3_dataset_no_overlap = DeltaDDGDataset(fold_3_no_overlap)\n","torch.save(fold_3_dataset_no_overlap, \"/content/drive/MyDrive/707/data/fold_3_dataset_no_overlap.pkl\")"],"metadata":{"id":"89iKgMewRssV"},"execution_count":null,"outputs":[]}]}